# Full Conversation on Entailment Cone Analysis Project with Complete Code

## Initial Code Review

I examined the codebase which includes:
- `entailment_theory.py`: Core classes for logical statements and entailment relations
- `deep_analysis.py`: Script for analyzing the entailment graph structure
- `independence_results.py`: Creates independence entailment graph
- `comprehensive_analysis.py`: Expands and analyzes the entailment graph
- `open_problems_analyzer.py`: Tools for analyzing open problems
- Various output files in `entailment_output/` directory

## Code Completion for deep_analysis.py

When examining line 468 in `deep_analysis.py`, I found it was incomplete and provided the full implementation:

```python
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
import os
import csv
from collections import defaultdict, Counter

# Use absolute path for output directory
OUTPUT_DIR = os.path.abspath("entailment_output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_graph_from_csv(filename="independence_graph.csv"):
    """Load the entailment graph from CSV file."""
    filepath = os.path.join(OUTPUT_DIR, filename)
    G = nx.DiGraph()
    
    with open(filepath, mode='r', encoding='utf-8') as file:
        reader = csv.reader(file)
        next(reader)  # Skip header
        for row in reader:
            source, target, relation = row
            G.add_edge(source, target, relation=relation)
    
    # Add node types based on relations
    for node in G.nodes():
        # If node has "Contains" outgoing edges, it's likely a system
        if any(G.edges[node, target].get('relation') == 'Contains' for target in G.successors(node)):
            G.nodes[node]['type'] = 'system'
        else:
            G.nodes[node]['type'] = 'theorem'
    
    return G

def analyze_cut_vertices(G):
    """Find and analyze cut vertices in the graph."""
    # Convert to undirected for cut vertex detection
    undirected_G = G.to_undirected()
    cut_vertices = list(nx.articulation_points(undirected_G))
    
    # Analyze what gets disconnected when each cut vertex is removed
    cut_vertex_analysis = []
    for vertex in cut_vertices:
        # Remove vertex and check components
        H = undirected_G.copy()
        H.remove_node(vertex)
        components = list(nx.connected_components(H))
        
        # Count systems and theorems in each component
        component_details = []
        for component in components:
            systems = [node for node in component if G.nodes[node].get('type') == 'system']
            theorems = [node for node in component if G.nodes[node].get('type') == 'theorem']
            component_details.append({
                'size': len(component),
                'systems': len(systems),
                'theorems': len(theorems),
                'nodes': sorted(list(component))
            })
        
        cut_vertex_analysis.append({
            'vertex': vertex,
            'type': G.nodes[vertex].get('type', 'unknown'),
            'components_after_removal': len(components),
            'component_details': component_details
        })
    
    # Save analysis to CSV
    filepath = os.path.join(OUTPUT_DIR, "cut_vertex_analysis.csv")
    with open(filepath, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["Vertex", "Type", "Components After Removal", "Component Details"])
        for analysis in cut_vertex_analysis:
            writer.writerow([
                analysis['vertex'],
                analysis['type'],
                analysis['components_after_removal'],
                '; '.join([f"Comp {i+1}: {comp['size']} nodes ({comp['systems']} sys, {comp['theorems']} thm)" 
                          for i, comp in enumerate(analysis['component_details'])])
            ])
    
    # Create visualization
    plt.figure(figsize=(12, 10))
    pos = nx.spring_layout(G, seed=42)
    
    # Draw nodes
    nx.draw_networkx_nodes(G, pos, 
                          nodelist=[n for n in G.nodes() if n not in cut_vertices],
                          node_color='lightblue', 
                          node_size=500)
    
    # Draw cut vertices in red
    nx.draw_networkx_nodes(G, pos, 
                          nodelist=cut_vertices,
                          node_color='red', 
                          node_size=700)
    
    # Draw edges
    nx.draw_networkx_edges(G, pos, arrows=True)
    
    # Draw labels
    nx.draw_networkx_labels(G, pos, font_size=10)
    
    plt.title("Entailment Graph with Cut Vertices Highlighted")
    plt.axis('off')
    plt.tight_layout()
    
    # Save figure
    plt.savefig(os.path.join(OUTPUT_DIR, "cut_vertices_visualization.png"), dpi=300)
    plt.close()
    
    print(f"Cut vertex analysis saved to {filepath}")
    print(f"Cut vertices visualization saved to {os.path.join(OUTPUT_DIR, 'cut_vertices_visualization.png')}")
    
    return cut_vertices, cut_vertex_analysis

def analyze_components(G):
    """Analyze connected components in the graph."""
    # Convert to undirected for component analysis
    undirected_G = G.to_undirected()
    components = list(nx.connected_components(undirected_G))
    
    # Analyze each component
    component_analysis = []
    for i, component in enumerate(components):
        systems = [node for node in component if G.nodes[node].get('type') == 'system']
        theorems = [node for node in component if G.nodes[node].get('type') == 'theorem']
        
        component_analysis.append({
            'component_id': i+1,
            'size': len(component),
            'systems': len(systems),
            'system_names': sorted(systems),
            'theorems': len(theorems),
            'theorem_names': sorted(theorems)
        })
    
    # Save analysis to CSV
    filepath = os.path.join(OUTPUT_DIR, "component_analysis.csv")
    with open(filepath, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["Component ID", "Size", "Systems", "System Names", "Theorems", "Theorem Names"])
        for analysis in component_analysis:
            writer.writerow([
                analysis['component_id'],
                analysis['size'],
                analysis['systems'],
                ', '.join(analysis['system_names']),
                analysis['theorems'],
                ', '.join(analysis['theorem_names'])
            ])
    
    # Create visualization with each component in a different color
    plt.figure(figsize=(12, 10))
    pos = nx.spring_layout(G, seed=42)
    
    # Generate colors for components
    colors = plt.cm.tab10(np.linspace(0, 1, len(components)))
    
    # Draw each component with a different color
    for i, component in enumerate(components):
        nx.draw_networkx_nodes(G, pos, 
                              nodelist=list(component),
                              node_color=[colors[i]],
                              node_size=500,
                              label=f"Component {i+1}")
    
    # Draw edges
    nx.draw_networkx_edges(G, pos, arrows=True)
    
    # Draw labels
    nx.draw_networkx_labels(G, pos, font_size=10)
    
    plt.title("Entailment Graph Components")
    plt.axis('off')
    plt.legend()
    plt.tight_layout()
    
    # Save figure
    plt.savefig(os.path.join(OUTPUT_DIR, "components_visualization.png"), dpi=300)
    plt.close()
    
    print(f"Component analysis saved to {filepath}")
    print(f"Components visualization saved to {os.path.join(OUTPUT_DIR, 'components_visualization.png')}")
    
    return components, component_analysis

def analyze_minimal_axioms():
    """Analyze patterns in minimal axiom systems."""
    filepath = os.path.join(OUTPUT_DIR, "minimal_axioms.csv")
    
    # Check if file exists
    if not os.path.exists(filepath):
        print(f"Warning: {filepath} not found. Skipping minimal axiom analysis.")
        return [], Counter()
    
    # Load minimal axiom data
    theorem_groups = defaultdict(list)
    system_counts = Counter()
    
    with open(filepath, mode='r', encoding='utf-8') as file:
        reader = csv.reader(file)
        next(reader)  # Skip header
        for row in reader:
            if len(row) < 2:
                continue
                
            theorem, minimal_systems_str = row
            if not minimal_systems_str.strip():
                minimal_systems = []
            else:
                minimal_systems = [s.strip() for s in minimal_systems_str.split(',')]
            
            # Group theorems by their minimal axiom systems
            key = ', '.join(sorted(minimal_systems))
            theorem_groups[key].append(theorem)
            
            # Count how many theorems each system is minimal for
            for system in minimal_systems:
                system_counts[system] += 1
    
    # Save theorem groupings to CSV
    output_filepath = os.path.join(OUTPUT_DIR, "theorem_groups.csv")
    with open(output_filepath, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(["Minimal Axiom Systems", "Theorems", "Count"])
        for systems, theorems in theorem_groups.items():
            writer.writerow([systems, ', '.join(theorems), len(theorems)])
    
    # Create heatmap visualization
    if system_counts and theorem_groups:
        try:
            # Get top systems and theorems
            top_systems = [system for system, _ in system_counts.most_common(10)]
            all_theorems = set()
            for theorems in theorem_groups.values():
                all_theorems.update(theorems)
            top_theorems = sorted(list(all_theorems))[:15]  # Limit to 15 theorems
            
            # Create matrix for heatmap
            matrix = np.zeros((len(top_theorems), len(top_systems)))
            
            # Fill matrix
            with open(filepath, mode='r', encoding='utf-8') as file:
                reader = csv.reader(file)
                next(reader)  # Skip header
                for row in reader:
                    if len(row) < 2:
                        continue
                        
                    theorem, minimal_systems_str = row
                    if theorem not in top_theorems:
                        continue
                        
                    if not minimal_systems_str.strip():
                        minimal_systems = []
                    else:
                        minimal_systems = [s.strip() for s in minimal_systems_str.split(',')]
                    
                    for system in minimal_systems:
                        if system in top_systems:
                            i = top_theorems.index(theorem)
                            j = top_systems.index(system)
                            matrix[i, j] = 1
            
            # Create heatmap
            plt.figure(figsize=(12, 10))
            plt.imshow(matrix, cmap='Blues', aspect='auto')
            
            # Add labels
            plt.yticks(range(len(top_theorems)), top_theorems)
            plt.xticks(range(len(top_systems)), top_systems, rotation=45, ha='right')
            
            plt.title("Theorem-Axiom System Relationships")
            plt.colorbar(label="Is Minimal")
            plt.tight_layout()
            
            # Save figure
            plt.savefig(os.path.join(OUTPUT_DIR, "minimal_axioms_heatmap.png"), dpi=300)
            plt.close()
            
            print(f"Minimal axiom analysis saved to {output_filepath}")
            print(f"Minimal axioms heatmap saved to {os.path.join(OUTPUT_DIR, 'minimal_axioms_heatmap.png')}")
        except Exception as e:
            print(f"Error creating heatmap: {e}")
    
    return theorem_groups, system_counts

def analyze_cycles(G):
    """Analyze fundamental cycles in the graph."""
    try:
        # Convert to undirected for cycle basis
        undirected_G = G.to_undirected()
        
        # Find cycle basis
        cycle_basis = nx.cycle_basis(undirected_G)
        
        # Analyze each cycle
        cycle_analysis = []
        for i, cycle in enumerate(cycle_basis):
            # Ensure cycle is a proper cycle (at least 3 nodes)
            if len(cycle) < 3:
                continue
                
            # Get edge types in the cycle
            edge_types = []
            for j in range(len(cycle)):
                source = cycle[j]
                target = cycle[(j+1) % len(cycle)]
                
                # Check if edge exists in original directed graph
                if G.has_edge(source, target):
                    edge_type = G.edges[source, target].get('relation', 'Unknown')
                    edge_types.append((source, target, edge_type))
                elif G.has_edge(target, source):
                    edge_type = G.edges[target, source].get('relation', 'Unknown')
                    edge_types.append((target, source, edge_type))
            
            # Count node types in the cycle
            systems = [node for node in cycle if G.nodes[node].get('type') == 'system']
            theorems = [node for node in cycle if G.nodes[node].get('type') == 'theorem']
            
            cycle_analysis.append({
                'cycle_id': i+1,
                'length': len(cycle),
                'nodes': cycle,
                'systems': len(systems),
                'theorems': len(theorems),
                'edge_types': edge_types
            })
        
        # Save analysis to CSV
        filepath = os.path.join(OUTPUT_DIR, "cycle_analysis.csv")
        with open(filepath, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            writer.writerow(["Cycle ID", "Length", "Nodes", "Systems", "Theorems", "Edge Types"])
            for analysis in cycle_analysis:
                writer.writerow([
                    analysis['cycle_id'],
                    analysis['length'],
                    ' -> '.join(analysis['nodes']),
                    analysis['systems'],
                    analysis['theorems'],
                    '; '.join([f"{s}->{t}: {r}" for s, t, r in analysis['edge_types']])
                ])
        
        # Visualize a few interesting cycles
        if cycle_analysis:
            # Sort cycles by length (descending)
            sorted_cycles = sorted(cycle_analysis, key=lambda x: x['length'], reverse=True)
            
            # Visualize top 3 cycles (or fewer if less available)
            for i, cycle_data in enumerate(sorted_cycles[:3]):
                cycle = cycle_data['nodes']
                
                plt.figure(figsize=(10, 8))
                pos = nx.spring_layout(G, seed=42)
                
                # Draw all nodes in light gray
                nx.draw_networkx_nodes(G, pos, 
                                      node_color='lightgray', 
                                      node_size=300)
                
                # Draw cycle nodes in blue
                nx.draw_networkx_nodes(G, pos, 
                                      nodelist=cycle,
                                      node_color='lightblue', 
                                      node_size=500)
                
                # Draw all edges in light gray
                nx.draw_networkx_edges(G, pos, 
                                      edge_color='lightgray',
                                      arrows=True,
                                      alpha=0.3)
                
                # Draw cycle edges in blue
                cycle_edges = [(cycle[j], cycle[(j+1) % len(cycle)]) for j in range(len(cycle))]
                nx.draw_networkx_edges(G, pos, 
                                      edgelist=cycle_edges,
                                      edge_color='blue',
                                      arrows=True,
                                      width=2)
                
                # Draw labels
                nx.draw_networkx_labels(G, pos, font_size=10)
                
                plt.title(f"Cycle {cycle_data['cycle_id']}: {' -> '.join(cycle)}")
                plt.axis('off')
                plt.tight_layout()
                
                # Save figure
                plt.savefig(os.path.join(OUTPUT_DIR, f"cycle_{cycle_data['cycle_id']}_visualization.png"), dpi=300)
                plt.close()
            
            print(f"Cycle analysis saved to {filepath}")
            print(f"Cycle visualizations saved to {os.path.join(OUTPUT_DIR, 'cycle_X_visualization.png')}")
        
        return cycle_basis, cycle_analysis
    
    except Exception as e:
        print(f"Error analyzing cycles: {e}")
        return [], []

def generate_summary_report(cut_vertices, components, theorem_groups, system_counts, cycle_analysis):
    """Generate a comprehensive summary report of all analyses."""
    report = [
        "# Entailment Cone Analysis Report",
        "",
        "## 1. Cut Vertices Analysis",
        "",
        f"Found {len(cut_vertices)} cut vertices in the entailment graph. These represent critical points",
        "in the logical structure of mathematics, where removing them would disconnect parts of the graph.",
        "",
        "Top cut vertices:",
    ]
    
    for vertex in cut_vertices[:5]:
        report.append(f"- {vertex}")
    
    report.extend([
        "",
        "## 2. Connected Components Analysis",
        "",
        f"The entailment graph contains {len(components)} connected components, suggesting",
        "distinct areas of mathematical reasoning that are not directly connected.",
        "",
        "Component details:",
    ])
    
    for i, component in enumerate(components):
        systems = [node for node in component if G.nodes[node].get('type') == 'system']
        theorems = [node for node in component if G.nodes[node].get('type') == 'theorem']
        report.append(f"- Component {i+1}: {len(component)} nodes ({len(systems)} systems, {len(theorems)} theorems)")
    
    report.extend([
        "",
        "## 3. Minimal Axiom Systems Analysis",
        "",
        f"Found {len(theorem_groups)} distinct patterns of minimal axiom requirements.",
        "This shows how theorems cluster based on their logical dependencies.",
        "",
        "Most common minimal axiom systems:",
    ])
    
    for system, count in system_counts.most_common(5):
        report.append(f"- {system}: required for {count} theorems")
    
    report.extend([
        "",
        "## 4. Cycle Analysis",
        "",
        f"Identified {len(cycle_analysis)} fundamental cycles in the entailment graph.",
        "These represent alternative proof paths or circular dependencies in the logical structure.",
        "",
        "Cycle statistics:",
        f"- Average cycle length: {np.mean([c['length'] for c in cycle_analysis]):.2f} nodes",
        f"- Longest cycle: {max([c['length'] for c in cycle_analysis])} nodes",
        f"- Shortest cycle: {min([c['length'] for c in cycle_analysis])} nodes",
        "",
        "## 5. Research Implications",
        "",